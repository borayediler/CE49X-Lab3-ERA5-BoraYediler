{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6dc64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Lab 5 analysis script for bias-variance exploration.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a618b8",
   "metadata": {},
   "source": [
    "Step 1.1 - Download the Data\n",
    "Data downloaded and added to the datasets folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7ba31",
   "metadata": {},
   "source": [
    "Step 1.2 - Load it with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651fc226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d02469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Path\n",
    "file_path = r\"C:\\Users\\EXCALIBUR\\OneDrive\\Masaüstü\\CE49X-Fall25-master\\datasets\\AirQualityUCI.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b668f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV File\n",
    "df = pd.read_csv(file_path, sep=';', decimal=',', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controls the first 5 line\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a137350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.3 - Handle the missing values that are indicated as -200\n",
    "df.replace(-200, pd.NA, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3440c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works only in the needed columns. Only these columns are converted into integers. Otherwise \n",
    "# Code did not create the graph below since it views the NAN Values as Strings.\n",
    "for col in ['T', 'RH', 'AH', 'CO(GT)']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3493b017",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Özellikler ve hedefte eksik olan satırları tamamen at\n",
    "df = df.dropna(subset=['T', 'RH', 'AH', 'CO(GT)']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010fc576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.4 - Select the featured columns for modelling\n",
    "features = ['T', 'RH', 'AH']\n",
    "target = 'CO(GT)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbcae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features] #The independent Variables\n",
    "y = df[target] #Dependent Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b53c721",
   "metadata": {},
   "source": [
    "Step 1.5 - Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d67541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fdbcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Öğrendiği Valuelar\n",
    "# Test - Test Ettiği Valuelar\n",
    "# test_size= 0.3 sets our Training and Test Distribution As ½70 - ½30\n",
    "# Random State Command makes our each result repeatable and not changing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8179126",
   "metadata": {},
   "source": [
    "Step 2 - Fit Models of Increasing Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a78216c",
   "metadata": {},
   "source": [
    "REGRESSION MODELS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddef723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f01e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "#MSE: How much model guesses wrongs returned as a numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = range(1, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25120939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I opened empty lists to record the training and test errors into them respectively.\n",
    "train_mse = []\n",
    "test_mse = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de71b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop trains the model with testing each degree.\n",
    "for d in degrees:\n",
    "    # 1) Transform features\n",
    "    poly = PolynomialFeatures(degree=d, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    # 2) Train Linear Regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "\n",
    "    # 3) Compute MSE on train & test\n",
    "    y_train_pred = model.predict(X_train_poly)\n",
    "    y_test_pred = model.predict(X_test_poly)\n",
    "\n",
    "    # Appending the errors to the list\n",
    "    train_mse.append(mean_squared_error(y_train, y_train_pred))\n",
    "    test_mse.append(mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b443192",
   "metadata": {},
   "source": [
    "Step 3 - Plot the Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb00a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First plot the graph\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36760953",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(degrees, train_mse, label='Training Error')\n",
    "plt.plot(degrees, test_mse, label='Testing Error')\n",
    "plt.xlabel('Model Complexity (Polynomial Degree)')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()\n",
    "plt.title('Bias–Variance Tradeoff')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d95576",
   "metadata": {},
   "source": [
    "Step 3.1 — Label the regions of underfitting, optimal complexity, and overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f0a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Best Degree, where the error is minimum.\n",
    "best_degree = degrees[np.argmin(test_mse)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94224163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e623e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axvline(best_degree, color='gray', linestyle='--', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underfitting\n",
    "plt.text(1.3, max(test_mse)*0.995, 'Underfitting\\n(low degree)',\n",
    "         fontsize=10, color='blue', ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef482d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal (biraz sola ve aşağıya alındı)\n",
    "plt.text(best_degree - 0.4, min(test_mse)*1.0015,\n",
    "         f'Optimal\\nDegree {best_degree}', fontsize=10, color='green', ha='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df26ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting (biraz yukarı ve sağa alındı)\n",
    "plt.text(9.5, max(test_mse)*0.997, 'Overfitting\\n(high degree)',\n",
    "         fontsize=10, color='red', ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03459fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
